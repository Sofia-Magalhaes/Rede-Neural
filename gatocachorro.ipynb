{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install tensorflow\n",
    "pip install tfLearn\n",
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dir - pega os dados do banco de training\n",
    "test_dir -  pega os dados do banco de teste\n",
    "img_size - muda o tamanho \n",
    "word_label - Se a word_label for igual a cat a array fica [1,0] (1 para gato e 0 para cachorro) e se for word_label igual a cachorro for [0,1] (0 para gato e 1 para cachorro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports e constantes para o processamento\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "#train data\n",
    "TRAIN_DIR = 'dogs-vs-cats/train'\n",
    "#teste data\n",
    "TEST_DIR = 'dogs-vs-cats/test1'\n",
    "# tamanho da imagem\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter as imagens e labels para informação em array \n",
    "# cedula para pegar as imagens do banco e fazer a separação dog(cachorro) cat(gato)\n",
    "\n",
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [cat,dog]\n",
    "    #                            [much cat, no dog]\n",
    "    if word_label == 'cat': return [1,0]\n",
    "    #                             [no cat, very doggo]\n",
    "    elif word_label == 'dog': return [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um training data\n",
    "# Processar a imagem de training e as labesl para arrays\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in os.listdir(TRAIN_DIR):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processando o test data\n",
    "# imagens e numeros\n",
    "\n",
    "#Com esta função, salvaremos e retornaremos os dados do array. Deste jeito,\n",
    "#se mudarmos apenas a estrutura da rede neural, e não algo com as imagens,\n",
    "#como o tamanho da imagem..etc..então podemos apenas carregar o arquivo array e economizar algum tempo de processamento. Enquanto estamos aqui,\n",
    "#podemos também criar uma função para processar os dados de teste. Estes são os dados reais do teste de competição,\n",
    "#  não os dados que usaremos para verificar a precisão do nosso algoritmo durante o teste. Esses dados não têm rótulo.\n",
    "\n",
    "# Essa função salva e retorna o dado da array. \n",
    "\n",
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in os.listdir(TEST_DIR):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# aqui roda o training\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#train_data = create_train_data()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# if you already have train data:\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtrain_data.npy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\npyio.py:413\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode)\n\u001b[0;32m    412\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 413\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[0;32m    414\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs)\n\u001b[0;32m    415\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\numpy\\lib\\format.py:741\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mhasobject:\n\u001b[0;32m    739\u001b[0m     \u001b[39m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[1;32m--> 741\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mObject arrays cannot be loaded when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    742\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mallow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    743\u001b[0m     \u001b[39mif\u001b[39;00m pickle_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    744\u001b[0m         pickle_kwargs \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    " # aqui roda o training\n",
    " #train_data = create_train_data()\n",
    "# if you already have train data:\n",
    " train_data = np.load('train_data.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " Definir a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tflearn\\initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que temos aqui é uma boa rede neural convolucional de 2 camadas, com uma camada totalmente conectada e, em seguida, a camada de saída. Tem sido debatido se uma camada totalmente conectada é útil ou não. Mas vamos deixar\n",
    "\n",
    "Este convnet exato foi bom o suficiente para reconhecer dígitos escritos à mão 28x28. Vamos ver como ele se sai com gatos e cachorros na resolução 50x50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 epochs é o conjunto de dados é passado na rede neural UMA VEZ.\n",
    "\n",
    "no nosso codigo var ter 5 epochs assim os dados vão passar 5 vezes\n",
    "\n",
    "\n",
    "Agora, nem sempre será o caso de você estar treinando a rede toda vez. Talvez primeiro você queira apenas ver como 3 épocas treinam, mas então, depois de 3, talvez você tenha terminado, ou talvez queira ver cerca de 5 épocas. Queremos salvar nosso modelo após cada sessão e recarregá-lo se tivermos uma versão salva, então adicionarei isto. \n",
    "\n",
    "Esse if serve para isso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir os train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, os dados de treinamento e os dados de teste são conjuntos de dados rotulados. Os dados de treinamento são os que ajustaremos à rede neural e os dados de teste são os que usaremos para validar os resultados. Os dados de teste estarão \"fora da amostra\", o que significa que os dados de teste serão usados apenas para testar a precisão da rede, não para treiná-la.\n",
    "\n",
    "Em seguida, vamos criar nossas matrizes de dados. Por alguma razão, lógica numpy típica como:\n",
    "\n",
    "array[:,0] e array[:,1]\n",
    "\n",
    "as epochs que \"fazem\" a melhora da acuracia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1148  | total loss: \u001b[1m\u001b[32m11.65576\u001b[0m\u001b[0m | time: 47.090s\n",
      "| Adam | epoch: 003 | loss: 11.65576 - acc: 0.4938 -- iter: 24448/24500\n",
      "Training Step: 1149  | total loss: \u001b[1m\u001b[32m11.31767\u001b[0m\u001b[0m | time: 48.204s\n",
      "| Adam | epoch: 003 | loss: 11.31767 - acc: 0.5085 | val_loss: 11.78924 - val_acc: 0.4880 -- iter: 24500/24500\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m tf\u001b[39m.\u001b[39mdisable_v2_behavior()\n\u001b[0;32m      3\u001b[0m tf\u001b[39m.\u001b[39mreset_default_graph()\n\u001b[1;32m----> 4\u001b[0m convnet \u001b[39m=\u001b[39m input_data(shape\u001b[39m=\u001b[39m[\u001b[39mNone\u001b[39;00m, IMG_SIZE, IMG_SIZE, \u001b[39m1\u001b[39m], name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m convnet \u001b[39m=\u001b[39m conv_2d(convnet, \u001b[39m32\u001b[39m, \u001b[39m5\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m convnet \u001b[39m=\u001b[39m max_pool_2d(convnet, \u001b[39m5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_data' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:c:\\Users\\sofia\\Desktop\\IaMl\\dogsvscats-0.001-2conv-basic.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m orig \u001b[39m=\u001b[39m img_data\n\u001b[0;32m     19\u001b[0m data \u001b[39m=\u001b[39m img_data\u001b[39m.\u001b[39mreshape(IMG_SIZE,IMG_SIZE,\u001b[39m1\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m model_out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict([data])[\u001b[39m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39margmax(model_out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m: str_label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDog\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[39melse\u001b[39;00m: str_label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCat\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if you need to create the data:\n",
    "# test_data = process_test_data()\n",
    "# if you already have some saved:\n",
    "test_data = np.load('test_data.npy', allow_pickle=True)\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "for num,data in enumerate(test_data[:12]):\n",
    "    # cat: [1,0]\n",
    "    # dog: [0,1]\n",
    "    \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,4,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    \n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 1: str_label='Dog'\n",
    "    else: str_label='Cat'\n",
    "        \n",
    "    y.imshow(orig,cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "falta acrescentar no projeto flip, rotate e predict "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
